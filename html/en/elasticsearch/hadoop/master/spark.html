<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Apache Spark support</title><meta name="generator" content="DocBook XSL Stylesheets V1.78.1" /><link rel="home" href="index.html" title="Elasticsearch for Apache Hadoop [master]" /><link rel="up" href="reference.html" title="Reference" /><link rel="prev" href="pig.html" title="Apache Pig support" /><link rel="next" href="mapping.html" title="Mapping and Types" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><meta content="width=device-width, initial-scale=1.0" name="viewport" /><link rel="shortcut icon" href="http://www.elasticsearch.org/content/themes/elasticsearch-org/favicon.ico" /><link rel="stylesheet" id="prettify-gc-syntax-highlighter-css" href="http://www.elasticsearch.org/content/plugins/prettify-gc-syntax-highlighter/prettify.css?ver=3.5.2" type="text/css" media="all" /><link rel="stylesheet" id="appStyles-css" href="http://www.elasticsearch.org/content/themes/elasticsearch-org/css/main.css?ver=1395693666" type="text/css" media="all" /><script type="text/javascript" src="http://www.elasticsearch.org/wp-includes/js/jquery/jquery.js?ver=1.8.3"></script><link rel="stylesheet" href="http://www.elasticsearch.org/content/themes/elasticsearch-org/style.css" type="text/css" media="all" /><script src="//cdn.optimizely.com/js/281975433.js"></script><script src="//fast.wistia.com/static/iframe-api-v1.js"></script><script type="text/javascript">
      jQuery(function() {
        jQuery('div.navheader+div').css('minHeight',jQuery('div.toc').height()+'px');
        jQuery('article.guide_content a[id]').each(function() { this.href='#'+this.id });
      });
    </script><link rel="stylesheet" type="text/css" href="styles.css?3" /></head><body class="single single-guide"><img src="http://ad.retargeter.com/seg?add=1235131&amp;t=2" width="1" height="1" style="position:absolute; visibility:hidden;" /><script type="text/javascript">
        if(jQuery('body').data('cookie') != "eu" || jQuery.cookie('allowCookies')){
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-12395217-2']);
        _gaq.push(['_trackPageview']);
        (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    }</script><!--[if lt IE 8]>
        <p class="chromeframe">You are using an outdated browser. <a href="http://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
      <![endif]--><header><nav role="navigation" id="mobile-nav-container" class="off-canvas-nav"><ul id="mobile-nav" class="menu"><li id="menu-item-75892" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-75892"><a href="/overview/">Overview</a><ul class="sub-menu"><li id="menu-item-75895" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-75895"><a href="/overview/">Overview</a></li><li id="menu-item-68760" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68760"><a href="/overview/elasticsearch/">Elasticsearch</a></li><li id="menu-item-75894" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-75894"><a href="/overview/marvel/">Marvel</a></li><li id="menu-item-68758" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68758"><a href="/overview/kibana/">Kibana</a></li><li id="menu-item-68756" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68756"><a href="/overview/kibana/installation/">Kibana Installation</a></li><li id="menu-item-68757" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68757"><a href="/overview/kibana/support/">Kibana Support</a></li><li id="menu-item-68759" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68759"><a href="/overview/logstash/">Logstash</a></li><li id="menu-item-74019" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-74019"><a href="/overview/hadoop/">Hadoop</a></li><li id="menu-item-75893" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-75893"><a href="/overview/elkdownloads/">ELK Downloads</a></li></ul></li><li id="menu-item-55" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-55"><a href="/resources/">Resources</a><ul class="sub-menu"><li id="menu-item-76342" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-76342"><a href="/guide/">Guide</a></li><li id="menu-item-4843" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-4843"><a href="/videos/">Videos</a></li></ul></li><li id="menu-item-657" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-657"><a href="/community/">Community</a></li><li id="menu-item-68802" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68802"><a href="/case-studies/">Case Studies</a></li><li id="menu-item-45" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-45"><a href="/blog/">Blog</a></li><li id="menu-item-12" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-12"><a target="_blank" href="http://elasticsearch.com">Company</a></li></ul><ul class="add-on"><li><a href="/overview/elkdownloads/">Download</a></li></ul></nav><div class="container"><div id="header-inner"><h1 id="header-logo"><a class="faux" href="http://www.elasticsearch.org">Elasticsearch</a></h1><nav role="navigation" id="main-nav-container" class="main-nav"><ul id="top-nav" class="menu"><li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-75892"><a href="/overview/">Overview</a></li><li class="menu-item menu-item-type-post_type menu-item-object-page current-menu-item page_item page-item-53 current_page_item menu-item-55"><a href="/resources/">Resources</a></li><li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-657"><a href="/community/">Community</a></li><li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-68802"><a href="/case-studies/">Case Studies</a></li><li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-45"><a href="/blog/">Blog</a></li><li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-12"><a target="_blank" href="http://elasticsearch.com">Company</a></li></ul><ul class="add-on"><li><a class="btn btn-primary" href="/overview/elkdownloads/">Download</a></li></ul></nav><div class="slide-trigger navigation" id="nav-trigger" aria-hidden="true"><span class="bar"></span><span class="bar"></span><span class="bar"></span></div><hr /><ul id="sub_nav"><li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-76342"><a href="/guide/">Guide</a></li><li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-4843"><a href="/videos/">Videos</a></li></ul></div></div></header><div class="global_wrapper"><div class="page_content"><div class="container"><section id="search_container" class="active"><form id="blog_search" role="search" action="/" method="get"><div class="blog_search_wrapper"><input id="s" name="s" class="search_term" type="text" placeholder="search" autocomplete="off" tabindex="1" /><input type="submit" class="search_submit" value=" " /><ul id="results"></ul></div></form></section><section class="full_width guide"><article class="guide_content"><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elasticsearch for Apache Hadoop
      [master]
    </a></span> » <span class="breadcrumb-link"><a href="reference.html">Reference </a></span> » <span class="breadcrumb-node">Apache Spark support</span></div><div class="navheader"><span class="prev"><a href="pig.html">
              « 
              Apache Pig support</a>
           
        </span><span class="next">
           
          <a href="mapping.html">Mapping and Types
               »
            </a></span></div><div class="chapter"><div class="titlepage"><div><div><h2 class="title"><a id="spark"></a>Apache Spark support<a href="https://github.com/elasticsearch/elasticsearch-hadoop/edit/master/docs/src/reference/asciidoc/core/spark.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h2></div></div></div><div class="toc"><dl><dt><span class="chapter"><a href="arch.html">Architecture</a></span></dt><dt><span class="chapter"><a href="configuration.html">Configuration</a></span></dt><dt><span class="chapter"><a href="configuration-runtime.html">Hadoop runtime options</a></span></dt><dt><span class="chapter"><a href="logging.html">Logging</a></span></dt><dt><span class="chapter"><a href="mapreduce.html">Map/Reduce integration</a></span></dt><dt><span class="chapter"><a href="cascading.html">Cascading support</a></span></dt><dt><span class="chapter"><a href="hive.html">Apache Hive integration</a></span></dt><dt><span class="chapter"><a href="pig.html">Apache Pig support</a></span></dt><dt><span class="chapter"><a href="spark.html">Apache Spark support</a></span></dt><dt><span class="chapter"><a href="mapping.html">Mapping and Types</a></span></dt><dt><span class="chapter"><a href="metrics.html">Hadoop Metrics</a></span></dt><dt><span class="chapter"><a href="troubleshooting.html">Troubleshooting</a></span></dt></dl></div><div class="blockquote"><table border="0" class="blockquote" summary="Block quote"><tr><td width="10%" valign="top"> </td><td width="80%" valign="top"><p><a class="ulink" href="http://spark.apache.org" target="_top">Apache Spark</a> is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala and Python, and an optimized engine that supports general execution graphs.</p></td><td width="10%" valign="top"> </td></tr><tr><td width="10%" valign="top"> </td><td colspan="2" align="right" valign="top">--<span class="attribution">
Spark website
</span></td></tr></table></div><p>Spark provides fast iterative/functional-like capabilities over large data sets, typically by <span class="emphasis"><em>caching</em></span> data in memory. As opposed to the rest of the libraries mentioned in this documentation, Apache Spark is computing framework that is not tied to Map/Reduce itself however it does integrate with Hadoop, mainly to HDFS.
elasticsearch-hadoop allows Elasticsearch to be used in Spark in two ways: through the dedicated support available since 2.1 or through the Map/Reduce bridge since 2.0</p><h3><a id="spark-installation"></a>Installation<a href="https://github.com/elasticsearch/elasticsearch-hadoop/edit/master/docs/src/reference/asciidoc/core/spark.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>Just like other libraries, elasticsearch-hadoop needs to be available in Spark’s classpath. As Spark has multiple deployment modes, this can translate to the target classpath, whether it is on only one node (as is the case with the local mode - which will be used through-out the documentation) or per-node depending on the desired infrastructure.</p><h3><a id="spark-native"></a>Native support<a href="https://github.com/elasticsearch/elasticsearch-hadoop/edit/master/docs/src/reference/asciidoc/core/spark.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>Added in 2.1.</p></div></div><p>elasticsearch-hadoop provides <span class="emphasis"><em>native</em></span> integration between Elasticsearch and Apache Spark, in the form of a RDD (Resilient Distributed Dataset) that can read data from Elasticsearch. The RDD is offered in two <span class="emphasis"><em>flavors</em></span>: one for Scala (which returns the data as Scala collections) and one for Java (which returns the data though <code class="literal">java.util</code> collections).</p><div class="important admon"><div class="icon"><img alt="Important" src="images/icons/important.png" /></div><div class="admon_content"><p>Whenever possible, consider using the <span class="emphasis"><em>native</em></span> integration as it offers the best performance and maximum flexibility.</p></div></div><h4><a id="spark-native-cfg"></a>Configuration<a href="https://github.com/elasticsearch/elasticsearch-hadoop/edit/master/docs/src/reference/asciidoc/core/spark.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>To configure one, one can set the various properties described in the <a class="xref" href="configuration.html" title="Configuration"><em>Configuration</em></a> chapter through the <a class="ulink" href="http://spark.apache.org/docs/1.0.1/programming-guide.html#initializing-spark" target="_top"><code class="literal">SparkCfg</code></a> object:</p><pre class="programlisting prettyprint lang-scala">import org.apache.spark.SparkConf

val conf = new SparkConf().setAppName(appName).setMaster(master)
conf.set("es.index.auto.create", "true")</pre><pre class="programlisting prettyprint lang-java">SparkConf conf = new SparkConf().setAppName(appName).setMaster(master);
conf.set("es.index.auto.create", "true");</pre><h4><a id="_reading_data_from_elasticsearch_5"></a>Reading data from Elasticsearch<a href="https://github.com/elasticsearch/elasticsearch-hadoop/edit/master/docs/src/reference/asciidoc/core/spark.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>Once configured, one should define the Elasticsearch RDD that <span class="emphasis"><em>streams</em></span> data from Elasticsearch to Spark.</p><p><strong>Scala. </strong>When using Scala, simply import the <code class="literal">org.elasticsearch.spark</code> package which, through the <a class="ulink" href="http://www.artima.com/weblogs/viewpost.jsp?thread=179766" target="_top"><span class="emphasis"><em>pimp my library</em></span></a> pattern, enriches the <code class="literal">SparkContext</code> API with <code class="literal">esRDD</code> methods:</p><pre class="programlisting prettyprint lang-scala">import org.apache.spark.SparkContext    <a id="CO41-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span>
import org.apache.spark.SparkContext._

import org.elasticsearch.spark._        <a id="CO41-2"></a><span><img src="images/icons/callouts/2.png" alt="" /></span>

...

val conf = ...
val sc = new SparkContext(conf)         <a id="CO41-3"></a><span><img src="images/icons/callouts/3.png" alt="" /></span>

val rdd = sc.esRDD("radio/artists")     <a id="CO41-4"></a><span><img src="images/icons/callouts/4.png" alt="" /></span></pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO41-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Spark Scala imports
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO41-2"><span><img src="images/icons/callouts/2.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
elasticsearch-hadoop Scala imports
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO41-3"><span><img src="images/icons/callouts/3.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
start Spark through its Scala API
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO41-4"><span><img src="images/icons/callouts/4.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
a dedicated <code class="literal">RDD</code> for Elasticsearch is created for index <code class="literal">radio/artists</code>
</p></td></tr></table></div><p>The method can be overloaded to specify an additional query or even a configuration <code class="literal">Map</code> (overriding <code class="literal">SparkConf</code>):</p><pre class="programlisting prettyprint lang-scala">...
import org.elasticsearch.spark._

...
val conf = ...
val sc = new SparkContext(conf)

sc.esRDD("radio/artists", "?me*") <a id="CO42-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span></pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO42-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
create an <code class="literal">RDD</code> streaming all the documents matching <code class="literal">me*</code> from index <code class="literal">radio/artists</code>
</p></td></tr></table></div><p>The documents from Elasticsearch are returned, by default, as Scala <a class="ulink" href="http://docs.scala-lang.org/overviews/collections/overview.html" target="_top">collections</a>, namely one <code class="literal">Map[String, Any]</code>
for each document, where the keys represent the field names and the value their respective values.</p><p><strong>Java. </strong>Java users have a dedicated <code class="literal">RDD</code> that works the same as its Scala counterpart however it returns the documents as native, <code class="literal">java.util</code> collections.
The main entry class is, <code class="literal">org.elasticsearch.hadoop.spark.api.java.JavaEsSpark</code>,similar to Spark’s <a class="ulink" href="https://spark.apache.org/docs/1.0.1/api/java/index.html?org/apache/spark/api/java/package-summary.html" target="_top">Java API</a>:</p><pre class="programlisting prettyprint lang-java">import org.apache.spark.api.java.JavaSparkContext;   <a id="CO43-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span>
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.SparkConf;

import org.elasticsearch.spark.java.api.JavaEsSpark; <a id="CO43-2"></a><span><img src="images/icons/callouts/2.png" alt="" /></span>
...

SparkConf conf = ...
JavaSparkContext jsc = new JavaSparkContext(conf);   <a id="CO43-3"></a><span><img src="images/icons/callouts/3.png" alt="" /></span>

JavaRDD&lt;Map&lt;String, Object&gt;&gt; esRDD = JavaEsSpark.esRDD(jsc, "radio/artists"); <a id="CO43-4"></a><span><img src="images/icons/callouts/4.png" alt="" /></span></pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO43-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Spark Java imports
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO43-2"><span><img src="images/icons/callouts/2.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
elasticsearch-hadoop Java imports
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO43-3"><span><img src="images/icons/callouts/3.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
start Spark through its Java API
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO43-4"><span><img src="images/icons/callouts/4.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
a dedicated <code class="literal">RDD</code> for Elasticsearch is created for index <code class="literal">radio/artists</code>
</p></td></tr></table></div><p>in a similar fashion one can use the overloaded <code class="literal">esRDD</code> methods to specify a query or pass a <code class="literal">Map</code> object for advanced configuration.
Let us see how this looks like, but this time around using <a class="ulink" href="http://docs.oracle.com/javase/1.5.0/docs/guide/language/static-import.html" target="_top">Java static imports</a>:</p><pre class="programlisting prettyprint lang-java">import static org.elasticsearch.spark.java.api.JavaEsSpark.*;             <a id="CO44-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span>

...
JavaRDD&lt;Map&lt;String, Object&gt;&gt; esRDD = esRDD(jsc, "radio/artists", "?me*"); <a id="CO44-2"></a><span><img src="images/icons/callouts/2.png" alt="" /></span></pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO44-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
statically import <code class="literal">JavaEsSpark</code> class
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO44-2"><span><img src="images/icons/callouts/2.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
create an <code class="literal">RDD</code> streaming all the documents starting with <code class="literal">me</code> from index <code class="literal">radio/artists</code>. Note the method does not have to be fully qualified due to the static import
</p></td></tr></table></div><p>By using the <code class="literal">JavaEsSpark</code> API, one gets a hold of Spark’s dedicated <code class="literal">JavaRDD</code> which are better suited in Java environments than the base <code class="literal">RDD</code> (due to its Scala
signatures). Moreover, the dedicated RDD returs Elasticsearch documents as proper Java collections so one does not have to deal with Scala collections (which
is typically the case with <code class="literal">RDD</code>s). This is particulary powerful when using Java 8, which we strongly advice as its
<a class="ulink" href="http://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html" target="_top">lambda expressions</a> make collection processing <span class="emphasis"><em>extremely</em></span>
concise.</p><p>To wit, let us assume one wants to filter the documents from the RDD and return only those that contain a value that contain <code class="literal">mega</code> (please ignore the fact one can and should do the filtering directly through Elasticsearch).</p><p>In versions prior to Java 8, the code would look something like this:</p><pre class="programlisting prettyprint lang-java">JavaRDD&lt;Map&lt;String, Object&gt;&gt; esRDD = esRDD(jsc, "radio/artists", "?me*");
JavaRDD&lt;Map&lt;String, Object&gt;&gt; filtered = esRDD.filter(
    new Function&lt;Map&lt;String, Object&gt;, Boolean&gt;() {
      @Override
      public Boolean call(Map&lt;String, Object&gt; map) throws Exception {
          for (Entry&lt;String, Object&gt; entry: map.entrySet()) {
              if (entry.getValue().toString().contains("mega")) {
                  return Boolean.TRUE;
              }
          }
          return Boolean.FALSE;
      }
    });</pre><p>with Java 8, the filtering becomes a one liner:</p><pre class="programlisting prettyprint lang-java">JavaRDD&lt;Map&lt;String, Object&gt;&gt; esRDD = esRDD(jsc, "radio/artists", "?me*");
JavaRDD&lt;Map&lt;String, Object&gt;&gt; filtered = esRDD.filter(
                m -&gt; m.values().stream().filter(v -&gt; v.contains("mega")));</pre><h4><a id="_writing_data_to_elasticsearch_4"></a>Writing data to Elasticsearch<a href="https://github.com/elasticsearch/elasticsearch-hadoop/edit/master/docs/src/reference/asciidoc/core/spark.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>With elasticsearch-hadoop, any <code class="literal">RDD</code> can be saved to Elasticsearch as long as its content can be translated into documents. When that is not the case, one can easily <span class="emphasis"><em>transform</em></span> the data
in Spark or plug-in their own customer <a class="link" href="configuration.html#configuration-serialization" title="Serializationedit"><code class="literal">ValueWriter</code></a>.</p><p><strong>Scala. </strong>Just like in the reading case, importing the elasticsearch-hadoop package enriches <code class="literal">SparkContext</code> with the <code class="literal">saveToEs</code> methods:</p><pre class="programlisting prettyprint lang-scala">import org.elasticsearch.spark._

...
val conf = ...
val sc = new SparkContext(conf)

val numbers = Map("one" -&gt; 1, "two" -&gt; 2, "three" -&gt; 3)
val airports = Map("OTP" -&gt; "Otopeni", "SFO" -&gt; "San Fran")

sc.makeRDD<a id="CO45-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span>(Seq(numbers, airports)).saveToEs<a id="CO45-2"></a><span><img src="images/icons/callouts/2.png" alt="" /></span>("spark/docs")</pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO45-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
<code class="literal">makeRDD</code> creates an ad-hoc <code class="literal">RDD</code> based on the collection specified; any other RDD (in Java or Scala) can be passed in
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO45-2"><span><img src="images/icons/callouts/2.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
index the content (namely the two <span class="emphasis"><em>documents</em></span> (numbers and airports)) in Elasticsearch under <code class="literal">spark/docs</code>
</p></td></tr></table></div><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>Scala users might be tempted to use <code class="literal">Seq</code> and the <code class="literal">→</code> notation for declaring <span class="emphasis"><em>root</em></span> objects (that is the JSON document) instead of using a <code class="literal">Map</code>. While similar, the first notation results in slightly different types that cannot be matched to a JSON document: <code class="literal">Seq</code> is an order sequence (in other words a list) while <code class="literal">←</code> creates a <code class="literal">Tuple</code> which is more or less an ordered, fixed number of elements. As such, a list of lists cannot be used as a document since it cannot be mapped to a JSON object; however it can be used freely within one. Hence why in the example above <code class="literal">Map(k→v)</code> was used instead of <code class="literal">Seq(k→v)</code></p></div></div><p><strong>Java. </strong>Just like before, under Java one should use the <code class="literal">JavaEsSpark</code> class which provides convenience methods and allows <span class="emphasis"><em>static</em></span> importing as exemplified below:</p><pre class="programlisting prettyprint lang-java">import static org.elasticsearch.spark.java.api.JavaEsSpark.*;     <a id="CO46-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span>

SparkContext cfg = ...
JavaSparkContext jsc = new JavaSparkContext(cfg);

Map&lt;String, ?&gt; numbers = ImmutableMap.of("one", 1, "two", 2);     <a id="CO46-2"></a><span><img src="images/icons/callouts/2.png" alt="" /></span>
Map&lt;String, ?&gt; airports = ImmutableMap.of("OTP", "Otopeni", "SFO", "San Fran");

JavaRDD&lt;Map&lt;String, ?&gt;&gt; javaRDD = jsc.parallelize(ImmutableList.of(doc1, doc2)); <a id="CO46-3"></a><span><img src="images/icons/callouts/3.png" alt="" /></span>
saveToEs(javaRDD, "spark/docs"); <a id="CO46-4"></a><span><img src="images/icons/callouts/4.png" alt="" /></span></pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO46-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
statically import <code class="literal">JavaEsSpark</code> class
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO46-2"><span><img src="images/icons/callouts/2.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
to simplify the example, use <a class="ulink" href="https://code.google.com/p/guava-libraries/" target="_top">Guava</a>(a dependency of Spark) <code class="literal">Immutable</code>* methods for simple <code class="literal">Map</code>, <code class="literal">List</code> creation
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO46-3"><span><img src="images/icons/callouts/3.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
create a simple <code class="literal">RDD</code> over the two collections; any other RDD (in Java or Scala) can be passed in
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO46-4"><span><img src="images/icons/callouts/4.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
index the content (namely the two <span class="emphasis"><em>documents</em></span> (numbers and airports)) in Elasticsearch under <code class="literal">spark/docs</code>
</p></td></tr></table></div><h3><a id="spark-mr"></a>Using the Map/Reduce layer<a href="https://github.com/elasticsearch/elasticsearch-hadoop/edit/master/docs/src/reference/asciidoc/core/spark.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>Another way of using Spark with Elasticsearch is through the Map/Reduce layer, that is by leveraging the dedicate <code class="literal">Input/OuputFormat</code> in elasticsearch-hadoop. However, unless one is stuck on
elasticsearch-hadoop 2.0, we <span class="emphasis"><em>strongly</em></span> recommend using the native integration as it offers significantly better performance and flexibility.</p><h4><a id="_configuration_3"></a>Configuration<a href="https://github.com/elasticsearch/elasticsearch-hadoop/edit/master/docs/src/reference/asciidoc/core/spark.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>Through elasticsearch-hadoop, Spark can integrate with Elasticsearch through its dedicated <code class="literal">InputFormat</code>, and in case of writing, through <code class="literal">OutputFormat</code>. These are described at length in the <a class="link" href="mapreduce.html" title="Map/Reduce integration">Map/Reduce</a> chapter so please refer to that for an in-depth explanation.</p><p>In short, one needs to setup a basic Hadoop <code class="literal">Configuration</code> object with the target Elasticsearch cluster and index, potentially a query, and she’s good to go.</p><p>From Spark’s perspective, they only thing required is setting up serialization - Spark relies by default on Java serialization which is convenient but fairly inefficient. This is the reason why Hadoop itself introduced its own serialization mechanism and its own types - namely <code class="literal">Writable</code>s. As such, <code class="literal">InputFormat</code> and <code class="literal">OutputFormat</code>s are required to return <code class="literal">Writables</code> which, out of the box, Spark does not understand.
The good news is, one can easily enable a different serialization (<a class="ulink" href="https://github.com/EsotericSoftware/kryo" target="_top">Kryo</a>) which handles the conversion automatically and also does this quite efficiently.</p><pre class="programlisting prettyprint lang-java">SparkConf sc = new SparkConf(); //.setMaster("local");
sc.set("spark.serializer", KryoSerializer.class.getName()); <a id="CO47-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span>

// needed only when using the Java API
JavaSparkContext jsc = new JavaSparkContext(sc);</pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO47-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Enable the Kryo serialization support with Spark
</p></td></tr></table></div><p>Or if you prefer Scala</p><pre class="programlisting prettyprint lang-scala">val sc = new SparkContext(...)
sc.set("spark.serializer", classOf[KryoSerializer].getName) <a id="CO48-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span></pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO48-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Enable the Kryo serialization support with Spark
</p></td></tr></table></div><p>Note that the Kryo serialization is used as a work-around for dealing with <code class="literal">Writable</code> types; one can choose to convert the types directly (from <code class="literal">Writable</code> to <code class="literal">Serializable</code> types) - which is fine however for getting started, the one liner above seems to be the most effective.</p><h4><a id="_reading_data_from_elasticsearch_6"></a>Reading data from Elasticsearch<a href="https://github.com/elasticsearch/elasticsearch-hadoop/edit/master/docs/src/reference/asciidoc/core/spark.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>To read data, simply pass in the <code class="literal">org.elasticsearch.hadoop.mr.EsInputFormat</code> class - since it supports both the <code class="literal">old</code> and the <code class="literal">new</code> Map/Reduce APIs, you are free to use either method on <code class="literal">SparkContext</code>'s, <code class="literal">hadoopRDD</code> (which we recommend for conciseness reasons) or <code class="literal">newAPIHadoopRDD</code>. Which ever you chose, stick with it to avoid confusion and problems down the road.</p><h5><a id="_emphasis_old_emphasis_literal_org_apache_hadoop_mapred_literal_api_3"></a><span class="emphasis"><em>Old</em></span> (<code class="literal">org.apache.hadoop.mapred</code>) API<a href="https://github.com/elasticsearch/elasticsearch-hadoop/edit/master/docs/src/reference/asciidoc/core/spark.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h5><pre class="programlisting prettyprint lang-java">JobConf conf = new JobConf();                   <a id="CO49-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span>
conf.set("es.resource", "radio/artists");       <a id="CO49-2"></a><span><img src="images/icons/callouts/2.png" alt="" /></span>
conf.set("es.query", "?q=me*");                 <a id="CO49-3"></a><span><img src="images/icons/callouts/3.png" alt="" /></span>

JavaPairRDD esRDD = jsc.hadoopRDD(conf, EsInputFormat.class,
                                        Text.class, MapWritable.class); <a id="CO49-4"></a><span><img src="images/icons/callouts/4.png" alt="" /></span>
long docCount = esRDD.count();</pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO49-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Create the Hadoop object (use the old API)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO49-2"><span><img src="images/icons/callouts/2.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Configure the source (index)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO49-3"><span><img src="images/icons/callouts/3.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Setup the query (optional)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO49-4"><span><img src="images/icons/callouts/4.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Create a Spark RDD on top of Elasticsearch through <code class="literal">EsInputFormat</code> - the key represent the doc id, the value the doc itself
</p></td></tr></table></div><p>The Scala version is below:</p><pre class="programlisting prettyprint lang-scala">val conf = new JobConf()                                <a id="CO50-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span>
conf.set("es.resource", "radio/artists")                <a id="CO50-2"></a><span><img src="images/icons/callouts/2.png" alt="" /></span>
conf.set("es.query", "?q=me*")                          <a id="CO50-3"></a><span><img src="images/icons/callouts/3.png" alt="" /></span>
val esRDD = sc.hadoopRDD(conf, classOf[EsInputFormat[Text, MapWritable]], <a id="CO50-4"></a><span><img src="images/icons/callouts/4.png" alt="" /></span>
                               classOf[Text], classOf[MapWritable]))
val docCount = esRDD.count();</pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO50-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Create the Hadoop object (use the old API)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO50-2"><span><img src="images/icons/callouts/2.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Configure the source (index)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO50-3"><span><img src="images/icons/callouts/3.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Setup the query (optional)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO50-4"><span><img src="images/icons/callouts/4.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Create a Spark RDD on top of Elasticsearch through <code class="literal">EsInputFormat</code>
</p></td></tr></table></div><h5><a id="_emphasis_new_emphasis_literal_org_apache_hadoop_mapreduce_literal_api_3"></a><span class="emphasis"><em>New</em></span> (<code class="literal">org.apache.hadoop.mapreduce</code>) API<a href="https://github.com/elasticsearch/elasticsearch-hadoop/edit/master/docs/src/reference/asciidoc/core/spark.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h5><p>As expected, the <code class="literal">mapreduce</code> API version is strikingly similar - replace <code class="literal">hadoopRDD</code> with <code class="literal">newAPIHadoopRDD</code> and <code class="literal">JobConf</code> with <code class="literal">Configuration</code>. That’s about it.</p><pre class="programlisting prettyprint lang-java">Configuration conf = new Configuration();       <a id="CO51-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span>
conf.set("es.resource", "radio/artists");       <a id="CO51-2"></a><span><img src="images/icons/callouts/2.png" alt="" /></span>
conf.set("es.query", "?q=me*");                 <a id="CO51-3"></a><span><img src="images/icons/callouts/3.png" alt="" /></span>

JavaPairRDD esRDD = jsc.newAPIHadoopRDD(conf, EsInputFormat.class,
                                              Text.class, MapWritable.class); <a id="CO51-4"></a><span><img src="images/icons/callouts/4.png" alt="" /></span>
long docCount = esRDD.count();</pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO51-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Create the Hadoop object (use the new API)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO51-2"><span><img src="images/icons/callouts/2.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Configure the source (index)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO51-3"><span><img src="images/icons/callouts/3.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Setup the query (optional)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO51-4"><span><img src="images/icons/callouts/4.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Create a Spark RDD on top of Elasticsearch through <code class="literal">EsInputFormat</code> - the key represent the doc id, the value the doc itself
</p></td></tr></table></div><p>The Scala version is below:</p><pre class="programlisting prettyprint lang-scala">val conf = new Configuration()                          <a id="CO52-1"></a><span><img src="images/icons/callouts/1.png" alt="" /></span>
conf.set("es.resource", "radio/artists")                <a id="CO52-2"></a><span><img src="images/icons/callouts/2.png" alt="" /></span>
conf.set("es.query", "?q=me*")                          <a id="CO52-3"></a><span><img src="images/icons/callouts/3.png" alt="" /></span>
val esRDD = sc.newHadoopRDD(conf, classOf[EsInputFormat[Text, MapWritable]], <a id="CO52-4"></a><span><img src="images/icons/callouts/4.png" alt="" /></span>
                                  classOf[Text], classOf[MapWritable]))
val docCount = esRDD.count();</pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO52-1"><span><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Create the Hadoop object (use the new API)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO52-2"><span><img src="images/icons/callouts/2.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Configure the source (index)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO52-3"><span><img src="images/icons/callouts/3.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Setup the query (optional)
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO52-4"><span><img src="images/icons/callouts/4.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
Create a Spark RDD on top of Elasticsearch through <code class="literal">EsInputFormat</code>
</p></td></tr></table></div></div><div class="navfooter"><span class="prev"><a href="pig.html">
              « 
              Apache Pig support</a>
           
        </span><span class="next">
           
          <a href="mapping.html">Mapping and Types
               »
            </a></span></div></article></section></div></div></div><footer><div id="footer_container" class="full_wrapper"><div class="container"><nav role="navigation"><ul id="footer_nav" class="menu"><li id="menu-item-36" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-36"><a target="_blank" href="http://elasticsearch.com">Company</a></li><li id="menu-item-74980" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-74980"><a href="/resources/">Resources</a></li><li id="menu-item-3106" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3106"><a href="/terms-of-use/">Terms</a></li><li id="menu-item-3107" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3107"><a href="/privacy-and-cookie-policy/">Privacy</a></li><li id="menu-item-3105" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3105"><a href="/contact/">Contact</a></li><li id="menu-item-39" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-39"><a href="/blog/">Blog</a></li></ul></nav><div id="social"><a href="https://twitter.com/elasticsearch" class="social_icons" target="_blank"><i class="twitter"></i></a><a href="https://www.facebook.com/elasticsearch" class="social_icons" target="_blank"><i class="facebook"></i></a></div><div id="footer_form"><label class="form_label">Sign up for updates!</label><div class="gf_browser_chrome gform_wrapper" id="gform_wrapper_4"><a id="gf_4" name="gf_4" class="gform_anchor"></a><form method="post" enctype="multipart/form-data" target="gform_ajax_frame_4" id="gform_4" action="/empty-template/#gf_4"><div class="gform_body"><ul id="gform_fields_4" class="gform_fields top_label description_below"><li id="field_4_6" class="gfield               gfield_contains_required"><label class="gfield_label" for="input_4_6">enter you email<span class="gfield_required">*</span></label><div class="ginput_container"><input name="input_6" id="input_4_6" type="email" value="" class="medium" tabindex="50" /></div></li><li id="field_4_2" class="gfield     gform_hidden"><input name="input_2" id="input_4_2" type="hidden" class="gform_hidden" value="813-MAM-392" /></li><li id="field_4_3" class="gfield     gform_hidden"><input name="input_3" id="input_4_3" type="hidden" class="gform_hidden" value="WEB.org" /></li><li id="field_4_4" class="gfield     gform_hidden"><input name="input_4" id="input_4_4" type="hidden" class="gform_hidden" value="WEB.org - Footer - Updates" /></li></ul></div><script type="text/javascript">//<![CDATA[
            jQuery(function(){
                jQuery('#gform_submit_button_4').click( function() {
                    if(window["gf_submitting_4"]){
                        return false;
                    }
                    if( !jQuery("#gform_4")[0].checkValidity || jQuery("#gform_4")[0].checkValidity()){
                        window["gf_submitting_4"]=true;
                    }
                });
            });
            //]]></script><div class="gform_footer top_label"><input type="submit" id="gform_submit_button_4" class="button gform_button" value="Submit" tabindex="51" /><input type="hidden" name="gform_ajax" value="form_id=4&amp;title=&amp;description=" /><input type="hidden" class="gform_hidden" name="is_submit_4" value="1" /><input type="hidden" class="gform_hidden" name="gform_submit" value="4" /><input type="hidden" class="gform_hidden" name="gform_unique_id" value="" /><input type="hidden" class="gform_hidden" name="state_4" value="WyJhOjA6e30iLCJmMjE2MmM2ZjUxYmQ4M2Q3ZmMzNzVlNmY2ODYyZTI2NCJd" /><input type="hidden" class="gform_hidden" name="gform_target_page_number_4" id="gform_target_page_number_4" value="0" /><input type="hidden" class="gform_hidden" name="gform_source_page_number_4" id="gform_source_page_number_4" value="1" /><input type="hidden" name="gform_field_values" value="" /></div></form></div><iframe style="display:none;width:0px; height:0px;" src="about:blank" name="gform_ajax_frame_4" id="gform_ajax_frame_4"></iframe><script type="text/javascript">//<![CDATA[
                    function gformInitSpinner_4(){jQuery('#gform_4').submit(function(){if(jQuery('#gform_ajax_spinner_4').length == 0){jQuery('#gform_submit_button_4, #gform_wrapper_4 .gform_next_button, #gform_wrapper_4 .gform_image_button').after('<' + 'img id="gform_ajax_spinner_4"  class="gform_ajax_spinner" src="http://www.elasticsearch.org/content/plugins/gravityforms/images/spinner.gif" alt="" />'); }} );}jQuery(document).ready(function($){gformInitSpinner_4();jQuery('#gform_ajax_frame_4').load( function(){var contents = jQuery(this).contents().find('*').html();var is_postback = contents.indexOf('GF_AJAX_POSTBACK') >= 0;if(!is_postback){return;}var form_content = jQuery(this).contents().find('#gform_wrapper_4');var is_redirect = contents.indexOf('gformRedirect(){') >= 0;var is_form = !(form_content.length <= 0 || is_redirect);if(is_form){jQuery('#gform_wrapper_4').html(form_content.html());jQuery(document).scrollTop(jQuery('#gform_wrapper_4').offset().top);if(window['gformInitDatepicker']) {gformInitDatepicker();}if(window['gformInitPriceFields']) {gformInitPriceFields();}var current_page = jQuery('#gform_source_page_number_4').val();gformInitSpinner_4();jQuery(document).trigger('gform_page_loaded', [4, current_page]);window['gf_submitting_4'] = false;}else if(!is_redirect){var confirmation_content = jQuery(this).contents().find('#gforms_confirmation_message').html();if(!confirmation_content){confirmation_content = contents;}setTimeout(function(){jQuery('#gform_wrapper_4').replaceWith('<' + 'div id=\'gforms_confirmation_message\' class=\'gform_confirmation_message_4\'' + '>' + confirmation_content + '<' + '/div' + '>');jQuery(document).scrollTop(jQuery('#gforms_confirmation_message').offset().top);jQuery(document).trigger('gform_confirmation_loaded', [4]);window['gf_submitting_4'] = false;}, 50);}else{jQuery('#gform_4').append(contents);if(window['gformRedirect']) {gformRedirect();}}jQuery(document).trigger('gform_post_render', [4, current_page]);} );} );</script><script type='text/javascript'> jQuery(document).ready(function(){jQuery(document).trigger('gform_post_render', [4, 1]) } );
                    //]]></script></div><div class="legal"><p>© 2014 All Rights Reserved - Elasticsearch </p><p>Apache Lucene and Lucene are trademarks of the Apache Software Foundation</p></div></div></div></footer><section id="cookie"><div class="container"><div class="eu">
                Elasticsearch uses cookies to provide a better user experience to visitors of our website. Read more about our cookie policy <a href="/privacy-and-cookie-policy/">here.</a><a data-action="accept" class="cta">Accept cookies</a></div><div class="uk">
                Elasticsearch uses cookies to provide a better user experience to visitors of our website. Read more about our cookie policy <a href="/privacy-and-cookie-policy/">here.</a><a data-action="dismiss" class="cta dismiss">X</a></div></div></section><script type="text/javascript">
      if (window.aiModifyParent) aiModifyParent();
      (function ($, $a, $title, $list) {
        $a = $('[id^="js-api-method-index"]');
        if (!$a.size()) return;
        $('.guide_content').addClass('js-client-docs');
        $list = $a.siblings('.itemizedlist').detach();
        $title = $(document.createElement('h2')).text('api methods')
        $a.parent().remove();
        $('.toc').first().append($(document.createElement('div')).addClass('js-api-method-index').append($title).append($list));
      }(jQuery));
    </script><script type="text/javascript">if(window.aiModifyParent) {aiModifyParent();}</script><script type="text/javascript" src="http://www.elasticsearch.org/content/plugins/prettify-gc-syntax-highlighter/prettify.js?ver=3.5.2"></script><script type="text/javascript" src="http://www.elasticsearch.org/content/plugins/prettify-gc-syntax-highlighter/launch.js?ver=3.5.2"></script><script type="text/javascript" src="http://s0.wp.com/wp-content/js/devicepx-jetpack.js?ver=201413"></script><script type="text/javascript" src="http://www.elasticsearch.org/content/themes/elasticsearch-org/js/global.min.js?ver=1395082598"></script><script type="text/javascript" src="http://www.elasticsearch.org/content/themes/elasticsearch-org/js/froogaloop.min.js?ver=1"></script><script type="text/javascript">
if(jQuery('body').data('cookie') != "eu" || jQuery.cookie('allowCookies')){
    document.write(unescape("%3Cscript src='" + document.location.protocol +
    "//munchkin.marketo.net/munchkin.js' type='text/javascript'%3E%3C/script%3E"));
}
</script><script>
if(jQuery('body').data('cookie') != "eu" || jQuery.cookie('allowCookies')){
    Munchkin.init('813-MAM-392');

    // crazyegg
    setTimeout(function(){var a=document.createElement("script");
    var b=document.getElementsByTagName("script")[0];
    a.src=document.location.protocol+"//dnn506yrbagrg.cloudfront.net/pages/scripts/0014/4686.js?"+Math.floor(new Date().getTime()/3600000);
    a.async=true;a.type="text/javascript";b.parentNode.insertBefore(a,b)}, 1);
}
</script></body></html>
